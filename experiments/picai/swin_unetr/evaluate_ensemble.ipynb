{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "`torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you have questions or suggestions, feel free to open an issue at https://github.com/DIAGNijmegen/picai_eval\n",
      "\n",
      "\n",
      "\n",
      "Please cite the following paper when using Report Guided Annotations:\n",
      "\n",
      "Bosma, J.S., et al. \"Semi-supervised learning with report-guided lesion annotation for deep learning-based prostate cancer detection in bpMRI\" to be submitted\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/DIAGNijmegen/Report-Guided-Annotation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from trainer import LitModel\n",
    "import torch \n",
    "from shared_modules.data_module_all import DataModule\n",
    "from shared_modules.utils import load_config\n",
    "from tqdm import tqdm\n",
    "from monai.metrics import DiceMetric\n",
    "from shared_modules.plotting import plot_metrics, plot_confusion, plot_difference\n",
    "from shared_modules.torch_metrics import PicaiMetric\n",
    "from shared_modules.post_transforms import get_post_transforms\n",
    "from monai.data import decollate_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PROB_MAPS = False\n",
    "SAVE_PREDS = False\n",
    "\n",
    "config = load_config(\"config.yaml\")\n",
    "config.data.data_dir = \"../../../data/\"\n",
    "config.data.json_list = \"../../../json_datalists/picai/all_samples.json\"\n",
    "gpu = 0\n",
    "config.gpus = [gpu]\n",
    "config.cache_rate = 1.0\n",
    "config.transforms.label_keys=[\"pca\", \"prostate\"]\n",
    "config.transforms.crop_key = \"prostate\"\n",
    "config.transforms.image_keys = [\"image\"]\n",
    "# config.transforms.image_keys = [\"t2w\", \"adc\", \"hbv\"]\n",
    "config.num_workers = 90\n",
    "\n",
    "label_key = config.transforms.label_keys[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "monai.networks.nets.swin_unetr SwinUNETR.__init__:img_size: Argument `img_size` has been deprecated since version 1.3. It will be removed in version 1.5. The img_size argument is not required anymore and checks on the input size are run during forward().\n"
     ]
    }
   ],
   "source": [
    "weights_folder = \"../../../gc_algorithms/base_container/models/swin_unetr/weights/\"\n",
    "models = []\n",
    "\n",
    "for i in range(5):\n",
    "    models.append(LitModel.load_from_checkpoint(f\"{weights_folder}f{i}.ckpt\", config=config, map_location=f\"cuda:{gpu}\"))\n",
    "    # disable randomness, dropout, etc...\n",
    "    models[-1].eval()\n",
    "    models[-1].to(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 1499/1499 [05:43<00:00,  4.37it/s]\n"
     ]
    }
   ],
   "source": [
    "dm = DataModule(\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "dm.setup(\"test\")\n",
    "dl = dm.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_map_post_transforms = get_post_transforms(key=\"prob\", \n",
    "                    orig_key=label_key,\n",
    "                    orig_transforms=dm.transforms[\"test\"],\n",
    "                    out_dir=f\"output/prob/\",\n",
    "                    keep_n_largest_components=0,\n",
    "                    output_postfix=\"\",\n",
    "                    output_dtype=\"float32\",\n",
    "                    save_mask=SAVE_PROB_MAPS) \n",
    "\n",
    "pca_post_transforms = get_post_transforms(key=\"pca\", \n",
    "                    orig_key=label_key,\n",
    "                    orig_transforms=dm.transforms[\"test\"],\n",
    "                    out_dir=f\"output/prob/\",\n",
    "                    keep_n_largest_components=0,\n",
    "                    output_postfix=\"\",\n",
    "                    output_dtype=\"float32\",\n",
    "                    save_mask=SAVE_PREDS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1499/1499 [15:29<00:00,  1.61it/s]\n"
     ]
    }
   ],
   "source": [
    "picai_metric_fn = PicaiMetric()\n",
    "\n",
    "all_probs = []\n",
    "all_gts = []\n",
    "\n",
    "\n",
    "for batch in tqdm(dl):\n",
    "    with torch.no_grad():\n",
    "        x = batch[\"image\"].to(gpu)\n",
    "\n",
    "        preds = []\n",
    "        probs = []\n",
    "        \n",
    "        for fold, model in enumerate(models):\n",
    "            logits = model.inferer(x)\n",
    "            probs.append(torch.sigmoid(logits[0,1])[None][None])\n",
    "            preds.append((probs[-1] > 0.5).float())\n",
    "            \n",
    "        \n",
    "    batch[\"pred\"] = (torch.mean(torch.stack(preds), dim=0) > 0.5).float()\n",
    "    batch[\"prob\"] = torch.mean(torch.stack(probs), dim=0)\n",
    "    \n",
    "    \n",
    "    # Reverts back to original size\n",
    "    batch[\"prob\"] = [prob_map_post_transforms(i)[\"prob\"] for i in decollate_batch(batch)]\n",
    "    batch[\"pca\"] = [pca_post_transforms(i)[\"pca\"] for i in decollate_batch(batch)]\n",
    "    \n",
    "    all_probs.append(batch[\"prob\"][0][0,...].cpu().numpy())\n",
    "    all_gts.append(batch[\"pca\"][0][0,...].cpu().numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import picai_eval\n",
    "from report_guided_annotation import extract_lesion_candidates\n",
    "\n",
    "metrics = picai_eval.evaluate(\n",
    "            y_det=all_probs,\n",
    "            y_true=all_gts,\n",
    "            y_det_postprocess_func=lambda pred: extract_lesion_candidates(pred, threshold=\"dynamic\")[0],\n",
    "            y_true_postprocess_func=lambda y: y,\n",
    "            num_parallel_calls=16\n",
    "        )\n",
    "\n",
    "metrics\n",
    "metrics.save(\"results/metrics.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(metrics,56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion(metrics, 56, threshold=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
